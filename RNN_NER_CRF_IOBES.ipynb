{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "#################Functions to load sentences and corresponding tags from text files###################\n",
    "#####################################################################################################\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import codecs\n",
    "import pickle\n",
    "from linear_crf_util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "train_path = \"data/CoNLL2003/train_iobes.pkl\"\n",
    "dev_path = \"data/CoNLL2003/dev_iobes.pkl\"\n",
    "test_path = \"data/CoNLL2003/test_iobes.pkl\"\n",
    "with open(train_path, 'rb') as f:\n",
    "    train_instances = pickle.load(f)\n",
    "with open(dev_path, 'rb') as f:\n",
    "    dev_instances = pickle.load(f)\n",
    "with open(test_path, 'rb') as f:\n",
    "    test_instances = pickle.load(f)\n",
    "    print('data loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('-docstart-',), ['o'])\n"
     ]
    }
   ],
   "source": [
    "print(train_instances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local embeddings size: (26873, 300)\n",
      "Vocabulary size 26873\n"
     ]
    }
   ],
   "source": [
    "###########################Load the dictionary and word indexes##################################\n",
    "import pickle\n",
    "import numpy as np\n",
    "path_dict = '../../data/CoNLL2003/vocab/local_dict_lower.pkl'\n",
    "path_emb = '../../data/CoNLL2003/vocab/local_emb_lower.pkl'\n",
    "with open(path_dict, 'rb') as f:\n",
    "    vocab, word2id, id2word = pickle.load(f)\n",
    "with open(path_emb, 'rb') as f:\n",
    "    local_glove_emb = pickle.load(f)\n",
    "print('Local embeddings size:', local_glove_emb.shape)\n",
    "print('Vocabulary size', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['b-loc', 'b-misc', 'b-org', 'b-per', 'i-loc', 'i-misc', 'i-org', 'i-per', 'o', '<pad>', '<end>', '<start>']\n",
    "tags = ['e-org', 'i-misc', 'e-misc', 'i-per', 'i-loc', 'o', 's-org', 'b-org', \n",
    "         'e-loc', 's-loc', 'i-org', 'e-per', 's-misc', 'b-per', 's-per', \n",
    "         'b-misc', 'b-loc', '<pad>', '<end>', '<start>']\n",
    "tag2id = {tag:i for i, tag in enumerate(tags)}\n",
    "id2tag = {i:tag for i, tag in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def sent2ids(text):\n",
    "    'Map words into indexes'\n",
    "    #print(text)\n",
    "    return [word2id[w] for w in text]\n",
    "\n",
    "def labels2ids(labels):\n",
    "    'Map labels into integers'\n",
    "    tags = []\n",
    "    for l in labels:\n",
    "        try:\n",
    "            tag_id = tag2id[l]\n",
    "        except:\n",
    "            tag_id = tag2id['<unk>']\n",
    "        tags.append(tag_id)\n",
    "    return tags\n",
    "\n",
    "\n",
    "def data_generator(sents, labels, batch_size=32, is_training=True, index=0):\n",
    "    if is_training:\n",
    "        select_indices = np.random.choice(len(sents), batch_size, replace=False)\n",
    "    else:\n",
    "        start = index\n",
    "        end = min(start + batch_size, len(sents)) \n",
    "        select_indices = list(range(start, end))\n",
    "    #select_indices = list(range(batch_size))\n",
    "    batch_sents = np.array(sents)[select_indices]\n",
    "    batch_labels = np.array(labels)[select_indices]\n",
    "    \n",
    "    \n",
    "    #batch_sents = [list(sent) for sent in batch_sents]\n",
    "    #batch_labels = [list(label) for label in batch_labels]\n",
    "    #print(batch_sents)\n",
    "    \n",
    "    batch_sents = list(map(sent2ids, batch_sents))\n",
    "    batch_labels = list(map(labels2ids, batch_labels))\n",
    "    \n",
    "    seq_lens = [len(s) for s in batch_sents]\n",
    "    seq_lens = torch.LongTensor(seq_lens)\n",
    "    max_len = max(seq_lens)\n",
    "    \n",
    "    batch_sents = [torch.LongTensor(s) for s in batch_sents]\n",
    "    batch_sents = pad_sequence(batch_sents, batch_first=True, padding_value=word2id['<pad>'])\n",
    "    \n",
    "    \n",
    "    batch_labels = [torch.LongTensor(s) for s in batch_labels]\n",
    "    batch_labels = pad_sequence(batch_labels, batch_first=True, padding_value=tag2id['<pad>'])\n",
    "    \n",
    "    if not is_training:\n",
    "        return batch_sents, batch_labels, seq_lens, end\n",
    "    \n",
    "    return batch_sents, batch_labels, seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent_words, train_sent_tags = list(zip(*train_instances))\n",
    "dev_sent_words,  dev_sent_tags = list(zip(*dev_instances))\n",
    "test_sent_words,  test_sent_tags = list(zip(*test_instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/richard/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "##############################Example#####################################\n",
    "batch_sents, batch_label, seq_lens = data_generator(train_sent_words, train_sent_tags, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################oken-level predictions#############\n",
    "from time import time\n",
    "import copy\n",
    "from sklearn.metrics import f1_score\n",
    "def evaluate(model, dev_sent_words, dev_sent_tags):\n",
    "    index = 0   \n",
    "    total_preds = []\n",
    "    total_tags = []\n",
    "    while index < len(dev_sent_words):\n",
    "        batch_sents, batch_tags, seq_lens, index = data_generator(dev_sent_words, \n",
    "                                                              dev_sent_tags, batch_size=batch_size, \n",
    "                                                              is_training=False, index=index)\n",
    "        _, pred_labels = model.decode(batch_sents, seq_lens)\n",
    "    #         preds = outs.view(-1, 3).argmax(1)\n",
    "    #         batch_tags = batch_tags.view(-1)\n",
    "\n",
    "        #ignore the padding tokens\n",
    "        for i, seq_len in enumerate(seq_lens):\n",
    "            preds = torch.LongTensor(pred_labels[i][:seq_lens[i]])\n",
    "            tag = batch_tags[i, :seq_lens[i]]\n",
    "            total_preds.append(preds)\n",
    "            total_tags.append(tag)\n",
    "    total_preds = torch.cat(total_preds) \n",
    "    total_tags = torch.cat(total_tags)\n",
    "\n",
    "    f1 = f1_score(total_tags, total_preds, average='macro')\n",
    "    return f1\n",
    "\n",
    "############################entity-level prediction#########################\n",
    "def evaluate_entity_pred(model, dev_sent_words, dev_sent_tags):\n",
    "    p_dict, total_predict_dict, total_entity_dict = Counter(), Counter(), Counter()\n",
    "    index = 0\n",
    "    predictions = []\n",
    "    while index < len(dev_sent_words):\n",
    "        batch_sents, batch_tags, seq_lens, index = data_generator(dev_sent_words, \n",
    "                                                              dev_sent_tags, batch_size=batch_size, \n",
    "                                                              is_training=False, index=index)\n",
    "        _, batch_max_ids = model.decode(batch_sents.to(device), seq_lens.to(device))\n",
    "        batch_p , batch_predict, batch_total = evaluate_batch_insts(batch_sents, \n",
    "                                                                    batch_max_ids, batch_tags, \n",
    "                                                                    seq_lens, id2tag)\n",
    "        p_dict += batch_p\n",
    "        total_predict_dict += batch_predict\n",
    "        total_entity_dict += batch_total\n",
    "    total_p = sum(list(p_dict.values()))\n",
    "    total_predict = sum(list(total_predict_dict.values()))\n",
    "    total_entity = sum(list(total_entity_dict.values()))\n",
    "    precision, recall, fscore = get_metric(total_p, total_entity, total_predict)\n",
    "    print(f\"[set Total] Prec.: {precision:.2f}, Rec.: {recall:.2f}, Micro F1: {fscore:.2f}\")\n",
    "    return precision, recall, fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 0\n",
    "# batch_size = 32\n",
    "# batch_sents, batch_tags, seq_lens, index = data_generator(train_sent_words, \n",
    "#                                                                   train_sent_tags, batch_size=batch_size, \n",
    "#                                                                   is_training=False, index=index)\n",
    "# model = NNCRF(label_size, len(vocab), 300, 200, 'va_w')\n",
    "# word_rep = model.embedder(batch_sents)\n",
    "# lstm_out, _ = model.encoder(word_rep, seq_lens)\n",
    "# lstm_out\n",
    "# #lstm_scores = model.hidden2tag(lstm_out)\n",
    "# #lstm_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training CRF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biGRU\n",
      "MVMA-G\n",
      "MVMA-G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/richard/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 313.955810546875\n",
      "[set Total] Prec.: 92.99, Rec.: 3.35, Micro F1: 6.47\n",
      "dev f1 score,  6.465237166991554\n",
      "Loss: 264.080810546875\n",
      "[set Total] Prec.: 71.26, Rec.: 10.01, Micro F1: 17.56\n",
      "dev f1 score,  17.55939206138409\n",
      "Loss: 231.61962890625\n",
      "[set Total] Prec.: 71.15, Rec.: 20.63, Micro F1: 31.99\n",
      "dev f1 score,  31.989562948467057\n",
      "Loss: 207.62451171875\n",
      "[set Total] Prec.: 71.48, Rec.: 27.97, Micro F1: 40.21\n",
      "dev f1 score,  40.20805612676908\n",
      "Loss: 199.576171875\n",
      "[set Total] Prec.: 71.54, Rec.: 33.79, Micro F1: 45.90\n",
      "dev f1 score,  45.902388844439365\n",
      "Loss: 200.5908203125\n",
      "[set Total] Prec.: 71.73, Rec.: 37.53, Micro F1: 49.28\n",
      "dev f1 score,  49.27632305822561\n",
      "Loss: 179.494384765625\n",
      "[set Total] Prec.: 71.20, Rec.: 40.36, Micro F1: 51.51\n",
      "dev f1 score,  51.514500537056925\n",
      "Loss: 169.135498046875\n",
      "[set Total] Prec.: 71.31, Rec.: 42.91, Micro F1: 53.58\n",
      "dev f1 score,  53.582685438117245\n",
      "Loss: 160.637939453125\n",
      "[set Total] Prec.: 71.84, Rec.: 44.92, Micro F1: 55.28\n",
      "dev f1 score,  55.27596562079321\n",
      "Loss: 165.0517578125\n",
      "[set Total] Prec.: 71.91, Rec.: 47.05, Micro F1: 56.89\n",
      "dev f1 score,  56.88708036622584\n",
      "Loss: 161.347900390625\n",
      "[set Total] Prec.: 72.11, Rec.: 48.99, Micro F1: 58.34\n",
      "dev f1 score,  58.34251929051007\n",
      "Loss: 141.22119140625\n",
      "[set Total] Prec.: 72.23, Rec.: 50.39, Micro F1: 59.36\n",
      "dev f1 score,  59.36353722613265\n",
      "Loss: 155.794921875\n",
      "[set Total] Prec.: 72.63, Rec.: 52.17, Micro F1: 60.72\n",
      "dev f1 score,  60.72477962781586\n",
      "Loss: 138.957275390625\n",
      "[set Total] Prec.: 73.09, Rec.: 53.80, Micro F1: 61.98\n",
      "dev f1 score,  61.981388134936026\n",
      "Loss: 131.95166015625\n",
      "[set Total] Prec.: 73.51, Rec.: 54.78, Micro F1: 62.78\n",
      "dev f1 score,  62.777242044358715\n",
      "Loss: 144.654541015625\n",
      "[set Total] Prec.: 73.82, Rec.: 55.65, Micro F1: 63.46\n",
      "dev f1 score,  63.461907503358276\n",
      "Loss: 131.75244140625\n",
      "[set Total] Prec.: 74.47, Rec.: 56.51, Micro F1: 64.26\n",
      "dev f1 score,  64.26179312984404\n",
      "Loss: 128.374755859375\n",
      "[set Total] Prec.: 75.13, Rec.: 56.83, Micro F1: 64.71\n",
      "dev f1 score,  64.71208201590495\n",
      "Loss: 134.135009765625\n",
      "[set Total] Prec.: 74.92, Rec.: 58.21, Micro F1: 65.52\n",
      "dev f1 score,  65.51756795151056\n",
      "Loss: 122.429443359375\n",
      "[set Total] Prec.: 75.26, Rec.: 59.02, Micro F1: 66.16\n",
      "dev f1 score,  66.15732880588568\n",
      "Loss: 117.66162109375\n",
      "[set Total] Prec.: 75.85, Rec.: 59.85, Micro F1: 66.90\n",
      "dev f1 score,  66.90498588899342\n",
      "Loss: 107.904052734375\n",
      "[set Total] Prec.: 76.35, Rec.: 60.35, Micro F1: 67.41\n",
      "dev f1 score,  67.4123507848482\n",
      "Loss: 113.595947265625\n",
      "[set Total] Prec.: 76.65, Rec.: 61.04, Micro F1: 67.96\n",
      "dev f1 score,  67.95952782462058\n",
      "Loss: 105.549560546875\n",
      "[set Total] Prec.: 77.00, Rec.: 61.75, Micro F1: 68.53\n",
      "dev f1 score,  68.53460353040067\n",
      "Loss: 116.59033203125\n",
      "[set Total] Prec.: 77.50, Rec.: 62.55, Micro F1: 69.23\n",
      "dev f1 score,  69.23076923076923\n",
      "Loss: 104.071044921875\n",
      "[set Total] Prec.: 77.33, Rec.: 62.92, Micro F1: 69.39\n",
      "dev f1 score,  69.38851257307229\n",
      "Loss: 114.159912109375\n",
      "[set Total] Prec.: 77.90, Rec.: 63.28, Micro F1: 69.83\n",
      "dev f1 score,  69.83006778716687\n",
      "Loss: 115.66455078125\n",
      "[set Total] Prec.: 77.79, Rec.: 63.73, Micro F1: 70.06\n",
      "dev f1 score,  70.06475485661424\n",
      "Loss: 102.458740234375\n",
      "[set Total] Prec.: 77.90, Rec.: 64.12, Micro F1: 70.34\n",
      "dev f1 score,  70.34062586541125\n",
      "Loss: 104.1279296875\n",
      "[set Total] Prec.: 77.98, Rec.: 64.86, Micro F1: 70.82\n",
      "dev f1 score,  70.81955163542814\n",
      "Loss: 92.038330078125\n",
      "[set Total] Prec.: 78.45, Rec.: 64.99, Micro F1: 71.09\n",
      "dev f1 score,  71.09065807639209\n",
      "Loss: 104.244140625\n",
      "[set Total] Prec.: 78.81, Rec.: 65.65, Micro F1: 71.63\n",
      "dev f1 score,  71.63055453543886\n",
      "Loss: 106.744384765625\n",
      "[set Total] Prec.: 79.09, Rec.: 65.70, Micro F1: 71.78\n",
      "dev f1 score,  71.77790034932892\n",
      "Loss: 84.64404296875\n",
      "[set Total] Prec.: 79.54, Rec.: 65.84, Micro F1: 72.04\n",
      "dev f1 score,  72.04419889502763\n",
      "Loss: 87.4287109375\n",
      "[set Total] Prec.: 79.18, Rec.: 66.24, Micro F1: 72.13\n",
      "dev f1 score,  72.13415192889215\n",
      "Loss: 89.774658203125\n",
      "[set Total] Prec.: 79.47, Rec.: 66.32, Micro F1: 72.31\n",
      "dev f1 score,  72.30529309237684\n",
      "Loss: 85.09765625\n",
      "[set Total] Prec.: 79.90, Rec.: 66.90, Micro F1: 72.82\n",
      "dev f1 score,  72.82220390217091\n",
      "Loss: 88.297119140625\n",
      "[set Total] Prec.: 80.16, Rec.: 67.20, Micro F1: 73.11\n",
      "dev f1 score,  73.1117824773414\n",
      "Loss: 84.6943359375\n",
      "[set Total] Prec.: 79.93, Rec.: 67.57, Micro F1: 73.23\n",
      "dev f1 score,  73.23301413588692\n",
      "Loss: 99.191162109375\n",
      "[set Total] Prec.: 80.41, Rec.: 67.92, Micro F1: 73.64\n",
      "dev f1 score,  73.6429157923547\n",
      "Loss: 103.1904296875\n",
      "[set Total] Prec.: 80.19, Rec.: 68.34, Micro F1: 73.80\n",
      "dev f1 score,  73.79611121206615\n",
      "Loss: 90.708984375\n",
      "[set Total] Prec.: 80.46, Rec.: 68.46, Micro F1: 73.98\n",
      "dev f1 score,  73.97708674304418\n",
      "Loss: 83.0732421875\n",
      "[set Total] Prec.: 80.17, Rec.: 68.50, Micro F1: 73.87\n",
      "dev f1 score,  73.87240221435704\n",
      "Loss: 78.7119140625\n",
      "[set Total] Prec.: 80.55, Rec.: 68.85, Micro F1: 74.24\n",
      "dev f1 score,  74.24008710643318\n",
      "Loss: 80.104736328125\n",
      "[set Total] Prec.: 80.94, Rec.: 69.02, Micro F1: 74.50\n",
      "dev f1 score,  74.50267962576075\n",
      "Loss: 88.113037109375\n",
      "[set Total] Prec.: 81.09, Rec.: 69.29, Micro F1: 74.73\n",
      "dev f1 score,  74.72547418096016\n",
      "Loss: 84.33544921875\n",
      "[set Total] Prec.: 80.89, Rec.: 69.79, Micro F1: 74.93\n",
      "dev f1 score,  74.92998464179239\n",
      "Loss: 95.06884765625\n",
      "[set Total] Prec.: 81.74, Rec.: 69.54, Micro F1: 75.15\n",
      "dev f1 score,  75.14776757297444\n",
      "Loss: 77.4716796875\n",
      "[set Total] Prec.: 81.30, Rec.: 69.96, Micro F1: 75.21\n",
      "dev f1 score,  75.20578923564\n",
      "Loss: 82.605224609375\n",
      "[set Total] Prec.: 81.03, Rec.: 70.21, Micro F1: 75.23\n",
      "dev f1 score,  75.23217022811288\n",
      "[set Total] Prec.: 74.64, Rec.: 62.80, Micro F1: 68.21\n",
      "##############################\n",
      "best val f1, test f1 75.2322 68.2115\n",
      "[(75.232, 68.2115)]\n"
     ]
    }
   ],
   "source": [
    "#Models defined in another file\n",
    "from linear_crf import NNCRF\n",
    "from torch import optim\n",
    "from time import time\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "label_size = len(tag2id)\n",
    "batch_size = 32\n",
    "epoch = 50\n",
    "trial_num = 1\n",
    "\n",
    "f1s = []\n",
    "for _ in range(trial_num):\n",
    "    model = NNCRF(label_size, len(vocab), 300, 200, 'gru')\n",
    "    #model = NNCRF(label_size, len(vocab), 32*32, 32, 'matmul')\n",
    "    model = model.to(device)\n",
    "    #model.load_pretrained_emb(path_emb, True)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.000001, weight_decay=1e-4)\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0)\n",
    "\n",
    "    best_f1 = -1\n",
    "    for i in range(epoch):\n",
    "        start = time()\n",
    "        model.train()\n",
    "        index = 0\n",
    "        #model.embedder.weight.retain_grad()\n",
    "        while index < len(train_sent_words):\n",
    "            batch_sents, batch_tags, seq_lens, index = data_generator(train_sent_words, \n",
    "                                                                  train_sent_tags, batch_size=batch_size, \n",
    "                                                                  is_training=False, index=index)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(batch_sents.to(device), seq_lens.to(device), batch_tags.to(device))\n",
    "            #loss = model(batch_sents.to(device), seq_lens, batch_tags.to(device))\n",
    "            loss.backward()\n",
    "            ######################For debugging####################\n",
    "            #print('loss', loss.item())\n",
    "            #temp = model.embedder.weight.grad.mean().item()\n",
    "            #print('grad', temp)\n",
    "            ##########################################\n",
    "            nn.utils.clip_grad_norm_(model.parameters(),5)\n",
    "            optimizer.step()\n",
    "            #print(index)\n",
    "            if index % 8000 == 0:\n",
    "                print('Loss:', loss.item())\n",
    "\n",
    "        #print('###################Debug training f1 scores:')\n",
    "        #f1 = evaluate(model, train_sent_words,train_sent_tags)\n",
    "        #print('Training f1 score', f1)\n",
    "        _, _, f1 = evaluate_entity_pred(model, dev_sent_words, dev_sent_tags)\n",
    "        print('dev f1 score, ', f1)\n",
    "        if best_f1 < f1:\n",
    "            best_f1 = f1\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _, _, f1 = evaluate_entity_pred(best_model, test_sent_words, test_sent_tags)\n",
    "    print('#'*30)\n",
    "    print('best val f1, test f1', round(best_f1, 4), round(f1, 4))\n",
    "    f1s.append((round(best_f1, 3),  round(f1, 4)))\n",
    "\n",
    "print(f1s)\n",
    "# model.eval()\n",
    "# batch_sents, batch_tags, seq_lens = data_generator(train_sent_words,train_sent_tags, batch_size=batch_size)\n",
    "# loss = model(batch_sents, seq_lens, batch_tags)\n",
    "# print(loss.item())\n",
    "#model2 = SequenceLabeling(len(vocab), 300, 300, label_size, path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.691829048632716"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "286.53/61.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sents_to_insts(sentences):\n",
    "    insts = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        words2ids = [word2id[w] for w in words]\n",
    "        insts.append(words2ids)\n",
    "    return insts\n",
    "\n",
    "def predict_insts(model, dev_sent_words, dev_sent_tags):\n",
    "    index = 0\n",
    "    predictions = []\n",
    "    while index < len(dev_sent_words):\n",
    "        batch_sents, batch_tags, seq_lens, index = data_generator(dev_sent_words, \n",
    "                                                              dev_sent_tags, batch_size=batch_size, \n",
    "                                                              is_training=False, index=index)\n",
    "        _, batch_max_ids = model.decode(batch_sents, seq_lens)\n",
    "        \n",
    "        for idx in range(len(batch_max_ids)):\n",
    "            length = seq_lens[idx]\n",
    "            prediction = batch_max_ids[idx][:length].tolist()\n",
    "            prediction = prediction[::-1]\n",
    "            prediction = [id2tag[l] for l in prediction]\n",
    "            predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "# def predict(model, sentences):\n",
    "#     sents = [sentences] if isinstance(sentences, str) else sentences\n",
    "#     insts = sents_to_insts(sents)\n",
    "\n",
    "#     test_batches = self.create_batch_data(insts)\n",
    "#     predictions = self.predict_insts(test_batches)\n",
    "#     if len(predictions) == 1:\n",
    "#         return predictions[0]\n",
    "#     else:\n",
    "#         return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/richard/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[set Total] Prec.: 72.43, Rec.: 7.96, Micro F1: 14.34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(72.43491577335375, 7.960282733086503, 14.344200151630021)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_entity_pred(model, dev_sent_words, dev_sent_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_defined_lstm import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tarlor series lstm linear simplified\n",
      "tarlor series lstm linear simplified\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(6, 3, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4, 6)\n",
    "lengths = torch.LongTensor([2,3,4])\n",
    "out, _ = lstm(x, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
