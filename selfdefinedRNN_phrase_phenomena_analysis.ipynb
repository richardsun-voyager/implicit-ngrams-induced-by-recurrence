{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gX6rKfD8CyNH"
   },
   "source": [
    "## Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1021,
     "status": "ok",
     "timestamp": 1596873868610,
     "user": {
      "displayName": "Richard Sun",
      "photoUrl": "",
      "userId": "07723018862498440951"
     },
     "user_tz": -480
    },
    "id": "1-AwwneWTY-F",
    "outputId": "1410042b-546c-4fe3-8cbd-2a7e904e7de1"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5379,
     "status": "ok",
     "timestamp": 1597469728944,
     "user": {
      "displayName": "Richard Sun",
      "photoUrl": "",
      "userId": "07723018862498440951"
     },
     "user_tz": -480
    },
    "id": "ejldGJAGCyNJ",
    "outputId": "0cd2e0db-307a-4b92-b274-81b902190009"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torchtext import data\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import argparse\n",
    "from helper import data_generator\n",
    "import sys; sys.argv=['']; del sys\n",
    "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "file = 'args/sst_attn_all.yaml'\n",
    "with open(file) as f:\n",
    "    args = yaml.load(f, Loader=yaml.Loader)\n",
    "    parser = argparse.ArgumentParser(description='attention')\n",
    "    config = parser.parse_args()\n",
    "    for k, v in args['common'].items():\n",
    "        setattr(config, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.batch_size = 1024\n",
    "# config.batch_size = 512#ag news\n",
    "# config.batch_size = 256#imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(config.dic_path, 'rb') as f:\n",
    "    vocab, word2id, id2word = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dg = data_generator(config, config.train_path)\n",
    "#train_eval_dg = data_generator(config, config.train_path, False)\n",
    "dev_dg = data_generator(config, config.dev_path, False)\n",
    "test_dg = data_generator(config, config.test_path, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98794"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dg.data_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2065,
     "status": "ok",
     "timestamp": 1597469731628,
     "user": {
      "displayName": "Richard Sun",
      "photoUrl": "",
      "userId": "07723018862498440951"
     },
     "user_tz": -480
    },
    "id": "DsDOEdpkCyNc"
   },
   "outputs": [],
   "source": [
    "from torch.nn import utils as nn_utils\n",
    "import torch\n",
    "from torch import optim\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from self_defined_gru_spectral import GRU\n",
    "# from self_defined_gru import GRU\n",
    "from self_defined_lstm_spectral import LSTM\n",
    "from self_defined_rnn_spectral import RNN\n",
    "from dynamic_lstm import dynamicLSTM\n",
    "from dynamic_gru import dynamicGRU\n",
    "from dynamic_rnn import dynamicRNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1072,
     "status": "ok",
     "timestamp": 1597469734506,
     "user": {
      "displayName": "Richard Sun",
      "photoUrl": "",
      "userId": "07723018862498440951"
     },
     "user_tz": -480
    },
    "id": "9fTKpWOECyNf"
   },
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, label_dim=1, rnn_type='elman'):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        #self.embeddings.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.affine = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.scale = scale\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        if rnn_type == 'elman':\n",
    "            self.rnn = RNN(embed_dim, hidden_dim, \n",
    "                          bidirectional=False)\n",
    "        elif rnn_type == 'gru':\n",
    "            self.rnn = GRU(embed_dim, hidden_dim, \n",
    "                          bidirectional=False)\n",
    "        else:\n",
    "            self.rnn = LSTM(embed_dim, hidden_dim, \n",
    "                          bidirectional=False)\n",
    "#         self.rnn = RNN(embed_dim, hidden_dim, \n",
    "#                       bidirectional=False)\n",
    "        self.linear = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        self.decoder = nn.Linear(hidden_dim, label_dim, bias=False)\n",
    "\n",
    "    # batch_size * sent_l * dim\n",
    "    def forward(self, seq_ids, seq_lengths=None):\n",
    "        '''\n",
    "        Args:\n",
    "            seq_ids: word indexes, batch_size, max_len, Long Tensor\n",
    "            seq_lengths: lengths of sentences, batch_size, Long Tensor\n",
    "        attention:\n",
    "            score = v h\n",
    "            att = softmax(score)\n",
    "        '''\n",
    "        \n",
    "        seq_embs = self.embeddings(seq_ids)\n",
    "        seq_embs = self.dropout(seq_embs)\n",
    "        #print(seq_embs.shape)\n",
    "        batch_size, max_len, hidden_dim = seq_embs.size()\n",
    "        # batch * max_len * hidden_states\n",
    "        #hidden_vecs = self.affine(seq_embs)\n",
    "        hidden_vecs, final_vec = self.rnn(seq_embs, seq_lengths)\n",
    "        #final_vec = self.linear(seq_embs)\n",
    "        final_vec = self.dropout(final_vec)\n",
    "        senti_scores = self.decoder(final_vec)\n",
    "        #multi class\n",
    "        if self.label_dim == 1:\n",
    "            probs = self.sigmoid(senti_scores)\n",
    "        else:\n",
    "            probs = self.softmax(senti_scores)\n",
    "            logits = torch.log(probs + 0.000000000001)\n",
    "            return logits, senti_scores\n",
    "        return probs, senti_scores\n",
    "    \n",
    "    def load_vector(self, path, trainable=False):\n",
    "        '''\n",
    "        Load pre-savedd word embeddings\n",
    "        '''\n",
    "        with open(path, 'rb') as f:\n",
    "            vectors = pickle.load(f)\n",
    "            print(\"Loaded from {} with shape {}\".format(path, vectors.shape))\n",
    "            #self.word_embed.weight = nn.Parameter(torch.FloatTensor(vectors))\n",
    "            np_data = torch.from_numpy(vectors)#/4\n",
    "            self.embeddings.weight.data.copy_(np_data)\n",
    "            self.embeddings.weight.requires_grad = trainable\n",
    "            print('embeddings loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1597469738705,
     "user": {
      "displayName": "Richard Sun",
      "photoUrl": "",
      "userId": "07723018862498440951"
     },
     "user_tz": -480
    },
    "id": "4mu6fXJWCyNk"
   },
   "outputs": [],
   "source": [
    "##Evaluation classification\n",
    "def evaluate_cls(dg, model, label_dim=1):\n",
    "    #Make prediction\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    #record the gold and the prediction\n",
    "    gold_labels = []\n",
    "    pred_labels = []\n",
    "    dg.reset_samples()\n",
    "    while dg.index<dg.data_len:\n",
    "        sent_ids, label_list, sent_lens = next(dg.get_ids_samples())\n",
    "        outputs, _ =  model(sent_ids.to(device), sent_lens.to(device))\n",
    "        if label_dim == 1:\n",
    "            preds = (outputs>0.5).squeeze()\n",
    "\n",
    "            gold_labels += list(label_list.cpu().numpy())\n",
    "            pred_labels += list(preds.cpu().numpy())\n",
    "            num = (preds.cpu() == label_list.bool()).sum().cpu().item()\n",
    "        else:\n",
    "            preds = outputs.argmax(1)\n",
    "            num = (label_list==preds.cpu()).sum().item()\n",
    "        count += num\n",
    "\n",
    "    accuracy = count*1.0/dg.data_len\n",
    "    print('Evaluation accuracy:', accuracy)\n",
    "    return accuracy\n",
    "\n",
    "#regression\n",
    "def evaluate_reg(dg, model):\n",
    "    #Make prediction\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    #record the gold and the prediction\n",
    "    error = 0\n",
    "    dg.reset_samples()\n",
    "    while dg.index<dg.data_len:\n",
    "        sent_ids, label_list, sent_lens = next(dg.get_ids_samples())\n",
    "        probs, scores = model(sent_ids.to(device), sent_lens.to(device))\n",
    "        #label_list.apply_(scale_value)\n",
    "        loss = loss_func(scores.squeeze(), label_list.float().to(device))\n",
    "        num = len(sent_lens)\n",
    "        error += loss.item() * num\n",
    "        count += num\n",
    "\n",
    "    mse = error/count\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_copy(model):\n",
    "    weights_path = 'weights_temp.pt'\n",
    "    torch.save(model.state_dict(), weights_path)\n",
    "    return torch.load(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55364,
     "status": "error",
     "timestamp": 1597469809620,
     "user": {
      "displayName": "Richard Sun",
      "photoUrl": "",
      "userId": "07723018862498440951"
     },
     "user_tz": -480
    },
    "id": "STPSEMhcCyNo",
    "outputId": "cf30a75b-52c9-4c61-d28e-03c636fd7d95"
   },
   "outputs": [],
   "source": [
    "# torch.manual_seed(555)\n",
    "# np.random.seed(555)\n",
    "import os\n",
    "label_dim = 1\n",
    "loss_func = nn.BCELoss()\n",
    "if label_dim>1:\n",
    "    loss_func = nn.NLLLoss()\n",
    "\n",
    "path = \"checkpoints/cuda1_sst_spectral_norm_gru(nobias)_20211009.pt\"\n",
    "if os.path.exists(path):\n",
    "    best_model = torch.load(path)\n",
    "else:\n",
    "    #torch.manual_seed(666)\n",
    "    #model = SimpleAttnClassifier(config.vocab_size, 100, 100, 1, scale)\n",
    "    hidden_dim = 300\n",
    "    model = SimpleClassifier(config.vocab_size, 300, hidden_dim, label_dim, 'gru')\n",
    "    #model.load_vector(config.emb_path, trainable=True)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    ##################################\n",
    "    ####Weight decay can influence the result, if the value is too large, the model will not converge after iterations\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=0.5, weight_decay=0.000000)\n",
    "    #optimizer = optim.Adagrad(model.parameters(), lr=0.5, weight_decay=0.00000, lr_decay=0.001)\n",
    "    #optimizer = optim.Adagrad(model.parameters(), lr=0.01, weight_decay=0.000001, lr_decay=0.001)\n",
    "\n",
    "    \n",
    "    loop_num = int(train_dg.data_len/config.batch_size)+1\n",
    "    best_model = None\n",
    "    best_acc = -1\n",
    "    train_acc = []\n",
    "    valid_acc = []\n",
    "    for i in range(15):\n",
    "        print('Epoch:', i)\n",
    "        print('#'*20)\n",
    "        \n",
    "        ##For gru\n",
    "        #optimizer = optim.Adagrad(model.parameters(), lr=0.01, weight_decay=0.00001, lr_decay=0.001)\n",
    "        #for lstm\n",
    "        #optimizer = optim.Adagrad(model.parameters(), lr=0.02, weight_decay=0.00002, lr_decay=0.0001)\n",
    "        #for elman\n",
    "        #optimizer = optim.Adagrad(model.parameters(), lr=0.02, weight_decay=0.00002, lr_decay=0.0001)\n",
    "        #for elman\n",
    "        optimizer = optim.Adagrad(model.parameters(), lr=0.02, weight_decay=0.00001, lr_decay=0.0001)\n",
    "\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        #shuffle the training set given the random seed\n",
    "        train_dg.shuffle_data()\n",
    "        #sequential sampling, use all the dataset\n",
    "        train_dg.reset_samples()\n",
    "        #model.embeddings.required_grad = config.update_emb\n",
    "        for j in range(loop_num):\n",
    "            model.zero_grad()\n",
    "            # generate dataset\n",
    "            sent_ids,  label_list, sent_lens = next(train_dg.get_sequential_ids_samples())\n",
    "            probs, scores = model(sent_ids.to(device), sent_lens.to(device))\n",
    "            #label_list.apply_(scale_value)\n",
    "            if label_dim == 1:\n",
    "                loss = loss_func(probs.squeeze(), label_list.float().to(device))#\n",
    "            else:\n",
    "                loss = loss_func(probs.squeeze(), label_list.to(device))\n",
    "            # Do the backward pass and update the gradient\n",
    "            #w_h = model.rnn.f_cell.weight_ih\n",
    "            #loss += w_h.norm(2)**2*0.0001#lstm\n",
    "            #loss += w_h.norm(2)**2*0.01#gru\n",
    "#             if i>5:\n",
    "#                 loss += w_h.norm(2)**2*0.01\n",
    "            loss.backward()\n",
    "#             nn.utils.clip_grad_norm_(model.parameters(),0.25)#0.05\n",
    "            nn.utils.clip_grad_norm_(model.parameters(),5)\n",
    "            optimizer.step()\n",
    "            if j%20== 0:\n",
    "                l = loss.cpu().item()\n",
    "                print('Sample Loss:{:.3f}'.format(l))\n",
    "\n",
    "        #Dev Evaluation\n",
    "        #print('Training Accuracy')\n",
    "        #t_acc = evaluate(train_eval_dg, model)\n",
    "        #print('Dev Accuracy')\n",
    "        dev_acc = evaluate_cls(dev_dg, model, label_dim)\n",
    "        #train_acc.append(t_acc)\n",
    "        valid_acc.append(dev_acc)\n",
    "        if best_acc < dev_acc:\n",
    "            best_acc = dev_acc\n",
    "            best_model_dict = get_weights_copy(model)\n",
    "            \n",
    "        #best_model = model\n",
    "#     #Test performance\n",
    "#     print('Training Accuracy')\n",
    "#     t_acc = evaluate(train_eval_dg, model)\n",
    "    best_model = copy.copy(model)\n",
    "    best_model.load_state_dict(best_model_dict)\n",
    "    #del best_model_dict\n",
    "    print('Best dev:', round(best_acc,4))\n",
    "    test_acc = evaluate_cls(test_dg, best_model, label_dim)\n",
    "    #Test performance       \n",
    "    print('Scale', scale, 'Test ACC:', round(test_acc,4))\n",
    "#     score_list = []\n",
    "#     for neg_phrase in negation_phrases_filtered:\n",
    "#         v = get_phrase_polarity(neg_phrase, best_model, hidden_dim)\n",
    "#         score_list.append(v)\n",
    "#     neg_phrase_scores.append(score_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "###newnew\n",
    "\n",
    "#best_model = torch.load(\"checkpoints/cuda1_sst_spectral_norm_gru(nobias)_20211009.pt\")\n",
    "#best_model = torch.load(\"checkpoints/cuda1_sst_spectral_norm_gru(nobias)_20220503.pt\")\n",
    "#torch.save(best_model, \"checkpoints/cuda1_sst_spectral_norm_gru(nobias)_20220503.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2163,
     "status": "ok",
     "timestamp": 1596872327132,
     "user": {
      "displayName": "Richard Sun",
      "photoUrl": "",
      "userId": "07723018862498440951"
     },
     "user_tz": -480
    },
    "id": "OdxaGl4sCyOI",
    "outputId": "797ad37b-57aa-4dec-dc59-e0cbb62a224a"
   },
   "outputs": [],
   "source": [
    "# #print('Best dev:', best_acc)\n",
    "# scale = 10\n",
    "# label_dim=4\n",
    "# # best_model = copy.copy(model)\n",
    "# # best_model.load_state_dict(best_model_dict)\n",
    "# valid_acc = evaluate_cls(dev_dg, best_model.to(device),label_dim)\n",
    "# test_acc = evaluate_cls(test_dg, best_model.to(device),label_dim)\n",
    "# #Test performance       \n",
    "# print('valid acc:', round(valid_acc*100,2), 'Test ACC:', round(test_acc*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from all_ngram_feature import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RuXWeGUICyO2"
   },
   "source": [
    "## Extract positive and negative adjectives\n",
    "Let us do an experiment, check whether the labels have strong relationship with certain words like the sentiment indicator \"good\", \"bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgv4qVlYCyO2"
   },
   "outputs": [],
   "source": [
    "texts, labels = zip(*train_dg.data_batch)\n",
    "text_length = [len(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CRTATPWCyO4"
   },
   "outputs": [],
   "source": [
    "texts2, labels2 = zip(*dev_dg.data_batch)\n",
    "text_length2 = [len(t) for t in texts2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kCJdH7v3CyO7"
   },
   "outputs": [],
   "source": [
    "texts3, labels3 = zip(*test_dg.data_batch)\n",
    "text_length3 = [len(t) for t in texts3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pV0bZn6pCyPL"
   },
   "outputs": [],
   "source": [
    "#Calculate the times that a token appears in a specified label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YpVb053gCyPO"
   },
   "outputs": [],
   "source": [
    "word_label_pair = []\n",
    "word_doc_freq = {}\n",
    "vocab = []\n",
    "for i, text in enumerate(texts):\n",
    "    for w in text:\n",
    "        word_doc_freq[w] = word_doc_freq.get(w, 0) + 1\n",
    "        \n",
    "for i, text in enumerate(texts):\n",
    "    label = labels[i]\n",
    "    for w in text:\n",
    "        word_doc_freq[w] = word_doc_freq.get(w, 0) + 1\n",
    "    word_label_pair += [(id2word[item], label) for item in text]\n",
    "    vocab += [id2word[item] for item in text]\n",
    "vocab = set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9E9bMJSBCyPS"
   },
   "outputs": [],
   "source": [
    "word_label_pair_freq = Counter(word_label_pair)\n",
    "#Get the ratio, a word appears in positive sentences: a word appears in negative sentences\n",
    "token_freq_pos = {}\n",
    "token_freq_neg = {}\n",
    "pos_tokens = []\n",
    "neg_tokens = []\n",
    "neutral_tokens = []\n",
    "total_diff_freq = 0\n",
    "#Note here, 1 means positive and 0 means negative\n",
    "for w in vocab:\n",
    "    freq_pos = word_label_pair_freq[(w, 1)]\n",
    "    freq_neg = word_label_pair_freq[(w, 0)]\n",
    "    token_freq_pos[word2id[w]] = freq_pos\n",
    "    token_freq_neg[word2id[w]] = freq_neg\n",
    "    if freq_pos+freq_neg == 0:\n",
    "        continue\n",
    "\n",
    "    if freq_pos-freq_neg !=0:\n",
    "        #We use 10\n",
    "        rate = (freq_pos-freq_neg)/(freq_pos+freq_neg)*1.0\n",
    "        if rate>0.5 and freq_pos>5:#positive tokens\n",
    "            pos_tokens.append(w)\n",
    "        if rate<-0.5 and freq_neg>5:\n",
    "            neg_tokens.append(w)\n",
    "\n",
    "    if abs(freq_pos-freq_neg)/(freq_pos+freq_neg)<0.1 and abs(freq_pos-freq_neg)<5:\n",
    "        neutral_tokens.append(w)\n",
    "#     if freq_pos-freq_neg !=0:\n",
    "#         #We use 10\n",
    "#         rate = (freq_pos-freq_neg)/(freq_pos+freq_neg)*1.0\n",
    "#         if freq_pos-freq_neg>20:#positive tokens\n",
    "#             pos_tokens.append(w)\n",
    "#         if freq_neg-freq_pos>20:\n",
    "#             neg_tokens.append(w)\n",
    "\n",
    "#     if abs(freq_pos-freq_neg)<5:\n",
    "#         neutral_tokens.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(neutral_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "pos_tokens_selected = []\n",
    "neg_tokens_selected = []\n",
    "for w in pos_tokens:\n",
    "    s = TextBlob(w)\n",
    "    if len(s.tags) == 0:\n",
    "        continue\n",
    "    if s.polarity>0.2 and s.tags[0][1]=='JJ':\n",
    "        pos_tokens_selected.append(w)\n",
    "for w in neg_tokens:\n",
    "    s = TextBlob(w)\n",
    "    if len(s.tags) == 0:\n",
    "        continue\n",
    "    if s.polarity<-0.2 and s.tags[0][1]=='JJ':\n",
    "        neg_tokens_selected.append(w)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_tokens_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# phi, scores = get_higher_degree_ngram(inputs, best_model, degree=1, hidden_dim=300)\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-sK28pJhCyPd"
   },
   "outputs": [],
   "source": [
    "pos_tokens_index = [word2id[w] for w in pos_tokens]\n",
    "neg_tokens_index = [word2id[w] for w in neg_tokens]\n",
    "neutral_tokens_index = [word2id[w] for w in neutral_tokens]\n",
    "pos_tokens_index_label1 = [token_freq_pos[w] for w in pos_tokens_index]\n",
    "pos_tokens_index_label0 = [token_freq_neg[w] for w in pos_tokens_index]\n",
    "pos_tokens_index_diff = [token_freq_pos[w]-token_freq_neg[w] for w in pos_tokens_index]\n",
    "\n",
    "neg_tokens_index_label1 = [token_freq_pos[w] for w in pos_tokens_index]\n",
    "neg_tokens_index_label0 = [token_freq_neg[w] for w in pos_tokens_index]\n",
    "neg_tokens_index_diff = [token_freq_pos[w]-token_freq_neg[w] for w in neg_tokens_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 300\n",
    "pos_token_ps = []\n",
    "negation_pos_token_ps = []\n",
    "neg_token_ps = []\n",
    "negation_neg_token_ps = []\n",
    "negation_id = word2id['not']\n",
    "rnn_cell = 'gru'\n",
    "if rnn_cell == 'gru':\n",
    "    get_polarity = gru_phrase_polarity_new\n",
    "if rnn_cell == 'lstm':\n",
    "    get_polarity = lstm_phrase_polarity_new\n",
    "if rnn_cell == 'elman':\n",
    "    get_polarity = rnn_phrase_polarity_new\n",
    "\n",
    "for w in pos_tokens_selected:\n",
    "    bigram = [negation_id] + [word2id[w]]\n",
    "    score1 = get_polarity([word2id[w]], best_model.to(device), hidden_dim)\n",
    "    score2 = get_polarity(bigram, best_model.to(device), hidden_dim)\n",
    "    pos_token_ps.append(score1)\n",
    "    negation_pos_token_ps.append(score2)\n",
    "for w in neg_tokens_selected:\n",
    "    bigram = [negation_id] + [word2id[w]]\n",
    "    score1 = get_polarity([word2id[w]], best_model, hidden_dim)\n",
    "    score2 = get_polarity(bigram, best_model, hidden_dim)\n",
    "    neg_token_ps.append(score1)\n",
    "    negation_neg_token_ps.append(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:1420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcc001825d0>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib# import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "#plt.style.use('default')\n",
    "labelsize = 18\n",
    "# rcParams['xtick.labelsize'] = labelsize\n",
    "# rcParams['ytick.labelsize'] = labelsize \n",
    "matplotlib.rc('xtick', labelsize=18) \n",
    "# matplotlib.rc('ytick', labelsize=10) \n",
    "# plt.style.use('seaborn-bright')\n",
    "\n",
    "# plt.style.use('ggplot')\n",
    "_ = plt.boxplot([pos_token_ps, negation_pos_token_ps, neg_token_ps, \n",
    "                 negation_neg_token_ps], patch_artist=True, \n",
    "                labels=['p-adj', '[-]p-adj', 'n-adj', '[-]n-adj'])\n",
    "plt.ylabel('Polarity Score', fontsize=15)\n",
    "plt.plot([0.5, 4.5], [0, 0], linestyle='--')\n",
    "# _ = plt.boxplot([pos_token_ps, negation_pos_token_ps], patch_artist=True)\n",
    "#plt.savefig(\"imgs/sst_gru_polarity_score_negate_adjective.pdf\", bbox_inches='tight', dpi=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RuXWeGUICyO2",
    "ixc1hrcbCyP2",
    "x4iARfG-CyP8"
   ],
   "name": "rnn_approx_classification_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
